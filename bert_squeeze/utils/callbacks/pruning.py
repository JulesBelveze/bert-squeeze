import logging
from typing import Any, Dict, List, Union

import pytorch_lightning as pl
import torch
from pytorch_lightning.callbacks.base import Callback
from torch.optim import Optimizer

STEP_OUTPUT = Union[torch.Tensor, Dict[str, Any]]


class ThresholdBasedPruning(Callback):
    """
    Callback for a very simple pruning strategy using weights magnitude like the following:
        f(wi)= {wi: if |wi| > thresh
                0:  if |wi| â‰¤ thresh}

    Args:
        threshold (float):
            value below which weights will be pruned
        start_pruning_epoch (int):
            epoch from which to apply the pruning strategy
    """

    def __init__(
        self, threshold: float, start_pruning_epoch: int = 10, *args: Any, **kwargs: Any
    ):
        super().__init__(*args, **kwargs)
        self.threshold = threshold
        self.start_pruning_epoch = start_pruning_epoch

    def on_before_optimizer_step(
        self,
        trainer: pl.Trainer,
        pl_module: pl.LightningModule,
        optimizer: Optimizer,
        optimizer_idx: int,
    ) -> None:
        """
        Method called before `optimizer.step()` to zero prune gradients

        Args:
            trainer (pl.Trainer):
                Lightning trainer
            pl_module (pl.LightningModule):
                Lightning module
            optimizer (Optimizer):
                optimizer used for training
            optimizer_idx (int):
                index of the optimizer to use

        """
        if pl_module.current_epoch >= self.start_pruning_epoch != -1:
            self._zero_pruned_gradients(pl_module)

    def on_train_epoch_end(
        self, trainer: pl.Trainer, pl_module: pl.LightningModule
    ) -> None:
        """
        Method called at the end of a training epoch to prune the model.

        Args:
            trainer (pl.Trainer):
                Lightning trainer
            pl_module (pl.LightningModule):
                Lightning module
        """
        if pl_module.current_epoch >= self.start_pruning_epoch != -1:
            logging.info(
                f"======== Pruning iteration {self.start_pruning_epoch - pl_module.current_epoch - 1} ========"
            )
            self._prune_model(pl_module)

    def on_fit_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:
        """
        Method called when fit ends.

        Args:
            trainer (pl.Trainer):
                Lightning trainer
            pl_module (pl.LightningModule):
                Lightning module
        """
        if self.start_pruning_epoch == -1:
            self._prune_model(pl_module)

    def _prune_model(self, pl_module: pl.LightningModule) -> None:
        """
        Method used to zero parameters which magnitude are below `self.threshold`.

        Args:
            pl_module (pl.LightningModule):
                Lightning module
        """
        for name, param in pl_module.named_parameters():
            if "weight" in name:
                param_mask = torch.abs(param) < self.threshold
                param.data[param_mask] = 0.0

    @staticmethod
    def _zero_pruned_gradients(pl_module: pl.LightningModule) -> None:
        """
        Method used for zeroing gradients of pruned weights

        Args:
            pl_module (pl.LightningModule):
                Lightning module
        """
        for name, param in pl_module.named_parameters():
            if "weight" in name:
                param_data = param.data.cpu()
                param_grad = param.grad.data.cpu()

                dummy_zero_tensor = torch.zeros_like(param_grad)
                param_grad = torch.where(param_data == 0.0, dummy_zero_tensor, param_grad)
                param.grad.data = param_grad.to(pl_module.device)


class SparsityBasedPruning(Callback):
    """
    Callback to achieve a given level of sparsity.

    Given a level of sparsity x it will prune n weights to such that (x * n)%
    of the model weights are pruned.
    """

    def __init__(
        self,
        sparsity_level: float = 0.0,
        layers_to_exclude: List[str] = None,
        *args: Any,
        **kwargs: Any,
    ):
        super().__init__(*args, **kwargs)
        self.sparsity_level = sparsity_level
        self.layers_to_exclude = layers_to_exclude

    def on_fit_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:
        """
        Method called when fit ends.

        Args:
            trainer (pl.Trainer):
                Lightning trainer
            pl_module (pl.LightningModule):
                Lightning module
        """
        if self.sparsity_level == 0.0:
            return

        # flatten all tensors and create a huge 1D tensor to get the threshold
        flatten_parameters = torch.cat(
            [param.view(-1) for param in pl_module.parameters()], dim=0
        )

        bottom_k, _ = torch.topk(
            flatten_parameters.abs(),
            int(self.sparsity_level * flatten_parameters.numel()),
            largest=False,
            sorted=True,
        )
        threshold = bottom_k.data[-1]
        self._prune_model(threshold, pl_module)

    @staticmethod
    def _prune_model(threshold: float, pl_module: pl.LightningModule) -> None:
        """
        Method used to zero parameters which magnitude are below `threshold`.

        Args:
            threshold (float):
                value below which weights will be pruned
            pl_module (pl.LightningModule):
                Lightning module
        """
        with torch.no_grad():
            for param in pl_module.parameters():
                mask = torch.lt(torch.abs(param), threshold)
                param.data[mask] = 0.0
